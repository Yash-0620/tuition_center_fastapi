from __future__ import annotations
import os
import json
import requests
from fastapi import APIRouter, Depends, Request, HTTPException, Form
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from sqlmodel import Session, select
from db import get_session
from models import Student, Tutor, User, Feedback
from dependencies import get_current_user

router = APIRouter(
    prefix="/student/{student_id}",
    tags=["Test Questions"]
)

# Gemini API setup (using direct HTTP requests)
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

_templates: Jinja2Templates | None = None


def init_templates(templates: Jinja2Templates) -> None:
    global _templates
    _templates = templates


# Helper function to call the Gemini API
def call_gemini_api(prompt: str) -> str:
    if not GEMINI_API_KEY:
        return "Error: GOOGLE_API_KEY environment variable not set."

    headers = {
        "Content-Type": "application/json"
    }
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ]
    }
    params = {
        "key": GEMINI_API_KEY
    }

    try:
        response = requests.post(GEMINI_API_URL, headers=headers, json=payload, params=params)
        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)
        response_json = response.json()

        # Extract the text from the response
        if 'candidates' in response_json and response_json['candidates']:
            return response_json['candidates'][0]['content']['parts'][0]['text']
        else:
            return "No content generated by the AI."

    except requests.exceptions.RequestException as e:
        return f"API Call Error: {e}"


# Helper function to get the most recent performance insights
def get_performance_insights(session: Session, student_id: int) -> str | None:
    """Fetches the most recent AI feedback for a student."""
    feedback = session.exec(
        select(Feedback)
        .where(Feedback.student_id == student_id)
        .order_by(Feedback.id.desc())
    ).first()
    if feedback and feedback.feedback_json:
        # Load and pretty-print the JSON for the AI prompt
        try:
            feedback_data = json.loads(feedback.feedback_json)
            return json.dumps(feedback_data, indent=2)
        except json.JSONDecodeError:
            return feedback.feedback_json  # Return raw text if JSON is invalid
    return None


# Helper function to construct the AI prompt
def create_ai_prompt(student_data: dict, form_data: dict, performance_data: str | None = None) -> str:
    """Constructs the AI prompt based on the type of request."""
    grade = student_data.get("grade")
    syllabus = student_data.get("syllabus")
    subject = form_data.get("subject")
    topics = form_data.get("topics")
    total_marks = form_data.get("totalMarks")
    mcq_count = form_data.get("mcqCount")
    short_answer_count = form_data.get("shortAnswerCount")
    long_answer_count = form_data.get("longAnswerCount")

    base_prompt = (
        f"Generate test questions for a student in Grade {grade}, following the {syllabus} syllabus.\n"
        f"Subject: {subject}\n"
        f"Topics: {topics}\n"
        f"Total Marks for Test: {total_marks}\n"
        f"Include the following types of questions:\n"
        f"- {mcq_count} multiple-choice questions (MCQ)\n"
        f"- {short_answer_count} short-answer questions\n"
        f"- {long_answer_count} long-answer questions\n\n"
        f"For each question, clearly specify the number of marks it is worth. The total marks for all questions should add up to {total_marks}."
    )

    if performance_data:
        # If performance insights are available, add them to the prompt
        insights_prompt = (
            f"\n\nAdditional context on student's past performance:\n"
            f"{performance_data}\n\n"
            f"Based on this feedback, please tailor the difficulty of the questions to address the student's weaknesses and reinforce their strengths."
        )
        return base_prompt + insights_prompt
    else:
        return base_prompt


# --- Routes for AI Question Generation ---
@router.get("/generate-questions", response_class=HTMLResponse)
def generate_questions_page(
        student_id: int,
        request: Request,
        session: Session = Depends(get_session),
        user: User = Depends(get_current_user)
):
    student = session.get(Student, student_id)
    if not student:
        raise HTTPException(status_code=404, detail="Student not found")

    tutor = session.get(Tutor, student.tutor_id)
    if not tutor or (user.user_type == "tutor" and tutor.id != user.tutor_id):
        raise HTTPException(status_code=403, detail="Not authorized")

    return _templates.TemplateResponse(
        "generate_questions.html",
        {"request": request, "student": student}
    )


@router.post("/generate-questions", response_class=HTMLResponse)
async def generate_questions(
        student_id: int,
        request: Request,
        question_type: str = Form(...),
        subject: str = Form(...),
        topics: str = Form(...),
        totalMarks: int = Form(...),
        mcqCount: int = Form(...),
        shortAnswerCount: int = Form(...),
        longAnswerCount: int = Form(...),
        session: Session = Depends(get_session),
        user: User = Depends(get_current_user)
):
    student = session.get(Student, student_id)
    if not student:
        raise HTTPException(status_code=404, detail="Student not found")

    tutor = session.get(Tutor, student.tutor_id)
    if not tutor or (user.user_type == "tutor" and tutor.id != user.tutor_id):
        raise HTTPException(status_code=403, detail="Not authorized")

    # Gather student data
    student_data = {
        "grade": student.grade,
        "syllabus": student.syllabus
    }

    # Gather form data
    form_data = {
        "subject": subject,
        "topics": topics,
        "totalMarks": totalMarks,
        "mcqCount": mcqCount,
        "shortAnswerCount": shortAnswerCount,
        "longAnswerCount": longAnswerCount
    }

    performance_data = None
    if question_type == "performance":
        performance_data = get_performance_insights(session, student_id)
        if not performance_data:
            # Handle case where no performance data exists
            return {
                "error": "No performance data found for this student. Generating questions based on syllabus instead."}

    # Create the AI prompt
    ai_prompt = create_ai_prompt(student_data, form_data, performance_data)

    # Call the AI model
    generated_questions = call_gemini_api(ai_prompt)

    # Return the generated questions to the user
    return _templates.TemplateResponse(
        "generated_questions_display.html",
        {"request": request, "student": student, "questions": generated_questions}
    )